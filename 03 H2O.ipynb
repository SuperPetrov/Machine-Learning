{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing H2O\n",
    "\n",
    "http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode)56-b12)\n",
      "  Starting server from C:\\Users\\Dopefish\\Anaconda3\\envs\\TF2\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\Dopefish\\AppData\\Local\\Temp\\tmpv72mzq_y\n",
      "  JVM stdout: C:\\Users\\Dopefish\\AppData\\Local\\Temp\\tmpv72mzq_y\\h2o_Dopefish_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\Dopefish\\AppData\\Local\\Temp\\tmpv72mzq_y\\h2o_Dopefish_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Europe/Berlin</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.26.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>22 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_Dopefish_k1jd6p</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.535 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       Europe/Berlin\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.26.0.3\n",
       "H2O cluster version age:    22 days\n",
       "H2O cluster name:           H2O_from_python_Dopefish_k1jd6p\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.535 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.7.4 final\n",
       "--------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(os.path.join(os.getcwd(),'train.csv.zip'))\n",
    "test=pd.read_csv(os.path.join(os.getcwd(),'test.csv.zip'))\n",
    "#train = h2o.import_file(os.path.join(os.getcwd(),'train.csv.zip'))\n",
    "#test = h2o.import_file(os.path.join(os.getcwd(),'test.csv.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights={1: 0.37062, 2: 0.49657,3:0.05947,4:0.018,5:0.018,6:0.018,7:0.018}\n",
    "class_weights={1: 0.37053, 2: 0.49657,3:0.05947,4:0.00106,5:0.01287,6:0.02698,7:0.03238}\n",
    "list_weight=compute_class_weight(class_weights,np.unique(train['Cover_Type']),train['Cover_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bal_acc2(y_true,y_pred):\n",
    "    #weights should be provided as list of weights for each class to sum up to 1\n",
    "    temp1=np.unique(y_true,return_counts=True)[1]\n",
    "    temp2=confusion_matrix(y_true,y_pred)\n",
    "    acc_bal=np.sum(np.diag(temp2)*(temp1/np.sum(temp1))/temp1)\n",
    "    weights=[0.37053, 0.49657, 0.05947, 0.00106, 0.01287, 0.02698, 0.03238]\n",
    "    acc_weig=np.sum(np.diag(temp2)*weights/temp1)\n",
    "    return (acc_weig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "my_score = make_scorer(bal_acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns\n",
    "target_col='Cover_Type'\n",
    "soil_type=[x for x in train.columns if 'Soil' in x]\n",
    "wild_type=[x for x in train.columns if 'Wilderness' in x]\n",
    "vert_dist=['Vertical_Distance_To_Hydrology']\n",
    "hor_dist=['Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Roadways',  'Horizontal_Distance_To_Fire_Points']\n",
    "hill_feat=['Hillshade_9am', 'Hillshade_Noon','Hillshade_3pm']\n",
    "other_feat=['Elevation', 'Aspect', 'Slope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_names = {\n",
    "0: 'Cathedral family - Rock outcrop complex, extremely stony.',\n",
    "1: 'Vanet - Ratake families complex, very stony.',\n",
    "2: 'Haploborolis - Rock outcrop complex, rubbly.',\n",
    "3: 'Ratake family - Rock outcrop complex, rubbly.',\n",
    "4: 'Vanet family - Rock outcrop complex complex, rubbly.',\n",
    "5: 'Vanet - Wetmore families - Rock outcrop complex, stony.',\n",
    "6: 'Gothic family.',\n",
    "7: 'Supervisor - Limber families complex.',\n",
    "8: 'Troutville family, very stony.',\n",
    "9: 'Bullwark - Catamount families - Rock outcrop complex, rubbly.',\n",
    "10: 'Bullwark - Catamount families - Rock land complex, rubbly.',\n",
    "11: 'Legault family - Rock land complex, stony.',\n",
    "12: 'Catamount family - Rock land - Bullwark family complex, rubbly.',\n",
    "13: 'Pachic Argiborolis - Aquolis complex.',\n",
    "14: 'unspecified in the USFS Soil and ELU Survey.',\n",
    "15: 'Cryaquolls - Cryoborolis complex.',\n",
    "16: 'Gateview family - Cryaquolls complex.',\n",
    "17: 'Rogert family, very stony.',\n",
    "18: 'Typic Cryaquolls - Borohemists complex.',\n",
    "19: 'Typic Cryaquepts - Typic Cryaquolls complex.',\n",
    "20: 'Typic Cryaquolls - Leighcan family, till substratum complex.',\n",
    "21: 'Leighcan family, tibbll substratum, extremely bouldery.',\n",
    "22: 'Leighcan family, till substratum - Typic Cryaquolls complex.',\n",
    "23: 'Leighcan family, extremely stony.',\n",
    "24: 'Leighcan family, warm, extremely stony.',\n",
    "25: 'Granile - Catamount families complex, very stony.',\n",
    "26: 'Leighcan family, warm - Rock outcrop complex, extremely stony.',\n",
    "27: 'Leighcan family - Rock outcrop complex, extremely stony.',\n",
    "28: 'Como - Legault families complex, extremely stony.',\n",
    "29: 'Como family - Rock land - Legault family complex, extremely stony.',\n",
    "30: 'Leighcan - Catamount families complex, extremely stony.',\n",
    "31: 'Catamount family - Rock outcrop - Leighcan family complex, extremely stony.',\n",
    "32: 'Leighcan - Catamount families - Rock outcrop complex, extremely stony.',\n",
    "33: 'Cryorthents - Rock land complex, extremely stony.',\n",
    "34: 'Cryumbrepts - Rock outcrop - Cryaquepts complex.',\n",
    "35: 'Bross family - Rock land - Cryumbrepts complex, extremely stony.',\n",
    "36: 'Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony.',\n",
    "37: 'Leighcan - Moran families - Cryaquolls complex, extremely stony.',\n",
    "38: 'Moran family - Cryorthents - Leighcan family complex, extremely stony.',\n",
    "39: 'Moran family - Cryorthents - Rock land complex, extremely stony.',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cat(df,soil_type,wild_type,soil_names,hill_feat):\n",
    "    #first add categories\n",
    "    df['soil_cat']=np.dot(df[soil_type],np.arange(len(soil_type)).reshape((len(soil_type),1)))\n",
    "    df['wild_cat']=np.dot(df[wild_type],np.arange(len(wild_type)).reshape((len(wild_type),1)))\n",
    "    df['soil_wild_cat']=df['soil_cat']*10+df['wild_cat']\n",
    "    #next add names\n",
    "    df[\"soil_name\"]=df['soil_cat'].map(soil_names)\n",
    "    #add some text features\n",
    "    #check how stony is the soil\n",
    "    df['stone_cat']=0\n",
    "    df['stone_cat']+=df[\"soil_name\"].str.contains(', rubbly')*1\n",
    "    df['stone_cat']+=df[\"soil_name\"].str.contains(', stony')*2\n",
    "    df['stone_cat']+=df[\"soil_name\"].str.contains('very stony')*3\n",
    "    df['stone_cat']+=df[\"soil_name\"].str.contains('extremely stony')*4\n",
    "    df['wild_stone']=df['stone_cat']*10+df['wild_cat']    \n",
    "    #check if Rock is in name\n",
    "    df['Rock_cat']=df[\"soil_name\"].str.contains('Rock outcrop')*1+df[\"soil_name\"].str.contains('Rock land')*2\n",
    "    df['if_Leighcan']=df[\"soil_name\"].str.contains('Leighcan')*1\n",
    "    df['if_Cryaquolls']=df[\"soil_name\"].str.contains('Cryaquolls')*1\n",
    "    df['if_Catamount']=df[\"soil_name\"].str.contains('Catamount')*1\n",
    "    df['if_Cryorthents']=df[\"soil_name\"].str.contains('Cryorthents')*1    \n",
    "    #relative distances\n",
    "    df['Hyd_2_Road']=df['Horizontal_Distance_To_Hydrology']/(df['Horizontal_Distance_To_Roadways']+df['Horizontal_Distance_To_Hydrology']+0.0001)\n",
    "    df['Hyd_2_Fire']=df['Horizontal_Distance_To_Hydrology']/(df['Horizontal_Distance_To_Fire_Points']+df['Horizontal_Distance_To_Hydrology']+0.0001)\n",
    "    df['Fire_2_Road']=df['Horizontal_Distance_To_Fire_Points']/(df['Horizontal_Distance_To_Roadways']+df['Horizontal_Distance_To_Fire_Points']+0.0001)\n",
    "    #add average shade\n",
    "    df['av_shade']=(df[hill_feat[0]]+df[hill_feat[1]]+df[hill_feat[2]])/3\n",
    "    df['dif_shade']=(df[hill_feat[0]]-df[hill_feat[2]])\n",
    "    #add sin of Aspect and slope\n",
    "    df['Sin_Aspect'] = np.sin(np.radians(df['Aspect']))\n",
    "    df['Sin_Slope'] = np.sin(np.radians(df['Slope']))\n",
    "    df[\"world_side\"]=np.logical_and(df['Aspect']>90,df['Aspect']<=180)*1+np.logical_and(df['Aspect']>180,df['Aspect']<=270)*2+np.logical_and(df['Aspect']>270,df['Aspect']<=360)*3\n",
    "    #below water\n",
    "    df['if_below']=(df['Vertical_Distance_To_Hydrology']<0)*1\n",
    "    df['Vertical_Distance_To_Hydrology']=np.abs(df['Vertical_Distance_To_Hydrology'])\n",
    "    #convert to sqrt\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new=add_cat(train,soil_type,wild_type,soil_names,hill_feat)\n",
    "train_new['weights']=(train_new['Cover_Type']>2)*1+(train_new['Cover_Type']<3)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below are features to use for traning\n",
    "learn_cols=['Elevation',\n",
    "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
    "       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n",
    "       'soil_cat', 'wild_cat', 'stone_cat', 'Hyd_2_Road', 'Hyd_2_Fire', 'Fire_2_Road', 'av_shade',\n",
    "       'Sin_Aspect', 'Sin_Slope','dif_shade',\"world_side\",'wild_stone','soil_wild_cat','if_below', 'Rock_cat', 'if_Leighcan',\n",
    "       'if_Cryaquolls', 'if_Catamount', 'if_Cryorthents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data to H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_h2o=h2o.H2OFrame(train_new[learn_cols+['Cover_Type','weights']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_h2o[\"Cover_Type\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Id columns\n",
    "# Make all categorical features as categorical\n",
    "#NOTE SUPER IMPORTANT OTHERWISE IT WILL NOT UNDERSTAND THAT IT IS CATEGORICAL PROBLEM AND WILL USE REGRESSION!!!\n",
    "train_h2o['Cover_Type'] = train_h2o['Cover_Type'].asfactor()\n",
    "train_h2o['soil_cat'] = train_h2o['soil_cat'].asfactor()\n",
    "train_h2o['wild_cat'] = train_h2o['wild_cat'].asfactor()\n",
    "train_h2o['stone_cat'] = train_h2o['stone_cat'].asfactor()\n",
    "train_h2o['world_side'] = train_h2o['world_side'].asfactor()\n",
    "train_h2o['wild_stone'] = train_h2o['wild_stone'].asfactor()\n",
    "train_h2o['soil_wild_cat'] = train_h2o['soil_wild_cat'].asfactor()\n",
    "train_h2o['Rock_cat'] = train_h2o['Rock_cat'].asfactor()\n",
    "\n",
    "#Predictor Columns\n",
    "x_col = learn_cols\n",
    "y_col = 'Cover_Type'\n",
    "\n",
    "#Split data into training and validation\n",
    "#d = train_h2o.split_frame(ratios = [0.8], seed = 42)\n",
    "#hf_train = d[0] # using 80% for training\n",
    "#hf_valid = d[1] # rest 20% for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the learning and fitting\n",
    "\n",
    "For the AutoML function, we just specify how long we want to train for and we’re set. I aslo limit the number of models to 30, set number of kfolds to 5 and make the model to save the cross_validation_predictions\n",
    "\n",
    "http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x: A list/vector of predictor column names or indexes. This argument only needs to be specified if the user wants to exclude columns from the set of predictors. If all columns (other than the response) should be used in prediction, then this does not need to be set.\n",
    "- validation_frame: This argument is ignored unless nfolds == 0, in which a validation frame can be specified and used for early stopping of individual models and early stopping of the grid searches (unless max_models or max_runtime_secs overrides metric-based early stopping). By default and when nfolds > 1, cross-validation metrics will be used for early stopping and thus validation_frame will be ignored.\n",
    "- leaderboard_frame: This argument allows the user to specify a particular data frame to use to score and rank models on the leaderboard. This frame will not be used for anything besides leaderboard scoring. If a leaderboard frame is not specified by the user, then the leaderboard will use cross-validation metrics instead, or if cross-validation is turned off by setting nfolds = 0, then a leaderboard frame will be generated automatically from the training frame.\n",
    "- blending_frame: Specifies a frame to be used for computing the predictions that serve as the training frame for the Stacked Ensemble models metalearner. If provided, all Stacked Ensembles produced by AutoML will be trained using Blending (a.k.a. Holdout Stacking) instead of the default Stacking method based on cross-validation.\n",
    "- fold_column: Specifies a column with cross-validation fold index assignment per observation. This is used to override the default, randomized, 5-fold cross-validation scheme for individual models in the AutoML run.\n",
    "- weights_column: Specifies a column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative weights are not allowed.\n",
    "- ignored_columns: (Optional, Python only) Specify the column or columns (as a list/vector) to be excluded from the model. This is the converse of the x argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "01:30:19.654: Project: automl_py_301_sid_8890\n",
      "01:30:19.655: AutoML job created: 2019.09.16 01:30:19.654\n",
      "01:30:19.655: AutoML: XGBoost is not available; skipping it.\n",
      "01:30:19.655: Disabling Algo: XGBoost as requested by the user.\n",
      "01:30:19.655: Build control seed: -1 (random)\n",
      "01:30:19.655: training frame: Frame key: automl_training_py_301_sid_8890    cols: 29    rows: 15120  chunks: 1    size: 1024096  checksum: -710655351287482984\n",
      "01:30:19.655: validation frame: NULL\n",
      "01:30:19.655: leaderboard frame: NULL\n",
      "01:30:19.655: response column: Cover_Type\n",
      "01:30:19.655: fold column: null\n",
      "01:30:19.655: weights column: [15120,1.0/1.285714285714286/2.0, 14.8 KB, {/127.0.0.1:54321:0:}]\n",
      "01:30:19.656: Setting stopping tolerance adaptively based on the training frame: 0.008132500607904443\n",
      "01:30:19.660: AutoML build started: 2019.09.16 01:30:19.660\n",
      "01:30:19.660: AutoML: starting GLM hyperparameter search\n",
      "\n",
      "███████████████████\n",
      "01:34:39.950: New leader: GBM_4_AutoML_20190916_013019, mean_per_class_error: 0.11944444444444445\n",
      "\n",
      "████████\n",
      "01:36:34.557: AutoML: starting GBM hyperparameter search\n",
      "\n",
      "██████████████████████\n",
      "01:49:17.564: AutoML: starting DeepLearning hyperparameter search\n",
      "\n",
      "█████\n",
      "01:58:27.61: AutoML: starting DeepLearning hyperparameter search\n",
      "\n",
      "█\n",
      "02:07:56.831: AutoML: starting DeepLearning hyperparameter search\n",
      "\n",
      "█| 100%\n",
      "\n",
      "02:34:24.55: New leader: StackedEnsemble_AllModels_AutoML_20190916_013019, mean_per_class_error: 0.11746031746031747\n",
      "02:34:24.55: AutoML build stopped: 2019.09.16 02:34:24.55\n",
      "02:34:24.55: AutoML build done: built 36 models\n",
      "02:34:24.56: AutoML duration:  1:04:04.395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aml = H2OAutoML(max_models=50, max_runtime_secs=3600, verbosity='info',nfolds=5,keep_cross_validation_predictions=True)\n",
    "aml.train(x = x_col, y = y_col,weights_column='weights', training_frame = train_h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the models\n",
    "\n",
    "Once the model is trained, you can access the Leaderboard. The leader model is stored at aml.leader and the leaderboard is stored at aml.leaderboard The leaderboard stores the snapshot of the top models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20190916_013019   </td><td style=\"text-align: right;\">              0.11746 </td><td style=\"text-align: right;\"> 0.332595</td><td style=\"text-align: right;\">0.309322</td><td style=\"text-align: right;\">0.0956801</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20190916_013019                       </td><td style=\"text-align: right;\">              0.119444</td><td style=\"text-align: right;\"> 0.428445</td><td style=\"text-align: right;\">0.341029</td><td style=\"text-align: right;\">0.116301 </td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20190916_003446   </td><td style=\"text-align: right;\">              0.119577</td><td style=\"text-align: right;\"> 0.335605</td><td style=\"text-align: right;\">0.311312</td><td style=\"text-align: right;\">0.0969153</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190916_013019_model_7          </td><td style=\"text-align: right;\">              0.120503</td><td style=\"text-align: right;\"> 0.41858 </td><td style=\"text-align: right;\">0.341691</td><td style=\"text-align: right;\">0.116753 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190916_013019</td><td style=\"text-align: right;\">              0.120503</td><td style=\"text-align: right;\"> 0.341712</td><td style=\"text-align: right;\">0.313851</td><td style=\"text-align: right;\">0.0985022</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20190916_013019                       </td><td style=\"text-align: right;\">              0.120899</td><td style=\"text-align: right;\"> 0.406715</td><td style=\"text-align: right;\">0.341182</td><td style=\"text-align: right;\">0.116405 </td></tr>\n",
       "<tr><td>GBM_4_AutoML_20190916_003446                       </td><td style=\"text-align: right;\">              0.121164</td><td style=\"text-align: right;\"> 0.417297</td><td style=\"text-align: right;\">0.341731</td><td style=\"text-align: right;\">0.11678  </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190916_003446</td><td style=\"text-align: right;\">              0.123082</td><td style=\"text-align: right;\"> 0.343468</td><td style=\"text-align: right;\">0.315141</td><td style=\"text-align: right;\">0.0993137</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20190916_003446                       </td><td style=\"text-align: right;\">              0.123611</td><td style=\"text-align: right;\"> 0.404348</td><td style=\"text-align: right;\">0.342094</td><td style=\"text-align: right;\">0.117028 </td></tr>\n",
       "<tr><td>GBM_2_AutoML_20190916_003446                       </td><td style=\"text-align: right;\">              0.124405</td><td style=\"text-align: right;\"> 0.404496</td><td style=\"text-align: right;\">0.343905</td><td style=\"text-align: right;\">0.118271 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(aml.leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after 900 sec\n",
    "StackedEnsemble_AllModels_AutoML_20190916_003446 \t0.119577\t0.335605\t0.311312\t0.0969153\n",
    "GBM_4_AutoML_20190916_003446 \t0.121164\t0.417297\t0.341731\t0.11678\n",
    "StackedEnsemble_BestOfFamily_AutoML_20190916_003446\t0.123082\t0.343468\t0.315141\t0.0993137\n",
    "GBM_3_AutoML_20190916_003446 \t0.123611\t0.404348\t0.342094\t0.117028 \n",
    "\n",
    "after 3600\n",
    "StackedEnsemble_AllModels_AutoML_20190916_013019 \t0.11746 \t0.332595\t0.309322\t0.0956801\n",
    "GBM_4_AutoML_20190916_013019 \t0.119444\t0.428445\t0.341029\t0.116301\n",
    "StackedEnsemble_AllModels_AutoML_20190916_003446 \t0.119577\t0.335605\t0.311312\t0.0969153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_AutoML_20190916_013019\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsMultinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.001671627565611271\n",
      "RMSE: 0.040885542256539426\n",
      "\n",
      "ModelMetricsMultinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0956801183048794\n",
      "RMSE: 0.3093220300995055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(aml.leader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the individual models results\n",
    "\n",
    "Note: here we will access the cross validation results;\n",
    ".cross_validation_holdout_predictions() - gives the cross validation results and .cross_validation_predictions() gives the result of each cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the models names\n",
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  GBM_4_AutoML_20190916_013019 accuracy  0.8805555555555555 bal accur 0.7762913379629628\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_7 accuracy  0.8794973544973544 bal accur 0.7745515370370372\n",
      "model  GBM_3_AutoML_20190916_013019 accuracy  0.879100529100529 bal accur 0.7755452962962962\n",
      "model  GBM_4_AutoML_20190916_003446 accuracy  0.8788359788359789 bal accur 0.7740087870370371\n",
      "model  GBM_3_AutoML_20190916_003446 accuracy  0.8763888888888889 bal accur 0.7701307546296297\n",
      "model  GBM_2_AutoML_20190916_003446 accuracy  0.8755952380952381 bal accur 0.7725390277777777\n",
      "model  GBM_2_AutoML_20190916_013019 accuracy  0.8751322751322751 bal accur 0.7662723796296296\n",
      "model  GBM_5_AutoML_20190916_013019 accuracy  0.871031746031746 bal accur 0.7682720092592593\n",
      "model  GBM_5_AutoML_20190916_003446 accuracy  0.8702380952380953 bal accur 0.7643194722222224\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_9 accuracy  0.8698412698412699 bal accur 0.7562264305555557\n",
      "model  GBM_1_AutoML_20190916_003446 accuracy  0.8697751322751323 bal accur 0.763402\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_6 accuracy  0.8689814814814815 bal accur 0.7619434583333333\n",
      "model  GBM_1_AutoML_20190916_013019 accuracy  0.8686507936507937 bal accur 0.7629510879629631\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_5 accuracy  0.8682539682539683 bal accur 0.7631425787037037\n",
      "model  DRF_1_AutoML_20190916_003446 accuracy  0.8654761904761905 bal accur 0.7422255879629631\n",
      "model  DRF_1_AutoML_20190916_013019 accuracy  0.8651455026455026 bal accur 0.7438511527777778\n",
      "model  XRT_1_AutoML_20190916_013019 accuracy  0.8650793650793651 bal accur 0.746198199074074\n",
      "model  XRT_1_AutoML_20190916_003446 accuracy  0.8642195767195767 bal accur 0.744158736111111\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_17 accuracy  0.8640873015873016 bal accur 0.758741412037037\n",
      "model  GBM_grid_1_AutoML_20190916_003446_model_2 accuracy  0.8617063492063493 bal accur 0.7636406574074075\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_11 accuracy  0.8607142857142858 bal accur 0.7596658333333334\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_16 accuracy  0.8564814814814815 bal accur 0.74982625\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_2 accuracy  0.843452380952381 bal accur 0.7405538657407408\n",
      "model  GBM_grid_1_AutoML_20190916_003446_model_10 accuracy  0.8356481481481481 bal accur 0.7291594907407407\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_4 accuracy  0.835515873015873 bal accur 0.7433992685185186\n",
      "model  GBM_grid_1_AutoML_20190916_003446_model_9 accuracy  0.832473544973545 bal accur 0.727672087962963\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_20 accuracy  0.8298280423280423 bal accur 0.7260188611111112\n",
      "model  GBM_grid_1_AutoML_20190916_003446_model_5 accuracy  0.8074074074074075 bal accur 0.7298229768518518\n",
      "model  DeepLearning_grid_1_AutoML_20190916_013019_model_1 accuracy  0.8037037037037037 bal accur 0.6859879305555556\n",
      "model  GBM_grid_1_AutoML_20190916_003446_model_6 accuracy  0.8023809523809524 bal accur 0.7138004027777778\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_15 accuracy  0.8 bal accur 0.721761375\n",
      "model  DeepLearning_grid_1_AutoML_20190916_003446_model_2 accuracy  0.7867724867724868 bal accur 0.6770246435185184\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_18 accuracy  0.7834656084656084 bal accur 0.7024568657407407\n",
      "model  DeepLearning_grid_1_AutoML_20190916_013019_model_2 accuracy  0.7752645502645502 bal accur 0.669399763888889\n",
      "model  DeepLearning_grid_1_AutoML_20190916_013019_model_3 accuracy  0.7740079365079365 bal accur 0.666049337962963\n",
      "model  DeepLearning_grid_1_AutoML_20190916_013019_model_4 accuracy  0.7511904761904762 bal accur 0.6343231712962963\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_14 accuracy  0.7488095238095238 bal accur 0.6951285416666667\n",
      "model  GBM_grid_1_AutoML_20190916_003446_model_7 accuracy  0.7416005291005291 bal accur 0.6844117407407408\n",
      "model  DeepLearning_grid_1_AutoML_20190916_003446_model_1 accuracy  0.7378968253968254 bal accur 0.6365581388888889\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_19 accuracy  0.7351851851851852 bal accur 0.6794126111111111\n",
      "model  GBM_grid_1_AutoML_20190916_003446_model_1 accuracy  0.7327380952380952 bal accur 0.6786787175925926\n",
      "model  GLM_grid_1_AutoML_20190916_013019_model_1 accuracy  0.714484126984127 bal accur 0.6706255138888889\n",
      "model  GLM_grid_1_AutoML_20190916_003446_model_1 accuracy  0.7114417989417989 bal accur 0.6699602685185185\n",
      "model  GBM_grid_1_AutoML_20190916_003446_model_4 accuracy  0.7037698412698413 bal accur 0.6570150648148149\n",
      "model  DeepLearning_1_AutoML_20190916_013019 accuracy  0.7035714285714286 bal accur 0.5724487638888888\n",
      "model  GBM_grid_1_AutoML_20190916_003446_model_3 accuracy  0.7029761904761904 bal accur 0.667199800925926\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_3 accuracy  0.698015873015873 bal accur 0.652551537037037\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_13 accuracy  0.6953042328042328 bal accur 0.6526523611111112\n",
      "model  DeepLearning_1_AutoML_20190916_003446 accuracy  0.6820767195767196 bal accur 0.5865648101851852\n",
      "model  DeepLearning_grid_1_AutoML_20190916_013019_model_5 accuracy  0.6819444444444445 bal accur 0.5769384814814814\n",
      "model  DeepLearning_grid_1_AutoML_20190916_003446_model_3 accuracy  0.6762566137566137 bal accur 0.5943634583333333\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_8 accuracy  0.6729497354497355 bal accur 0.6342545833333334\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_1 accuracy  0.6641534391534392 bal accur 0.621079388888889\n",
      "model  GBM_grid_1_AutoML_20190916_003446_model_8 accuracy  0.6619047619047619 bal accur 0.6292285787037036\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_10 accuracy  0.5941798941798941 bal accur 0.46859737500000004\n",
      "model  GBM_grid_1_AutoML_20190916_013019_model_21 accuracy  0.5790343915343915 bal accur 0.49317030092592584\n"
     ]
    }
   ],
   "source": [
    "for model in model_ids:\n",
    "    temp_model=h2o.get_model(model)\n",
    "    temp_prediction=temp_model.cross_validation_holdout_predictions()\n",
    "    if temp_prediction is None:\n",
    "        pass\n",
    "    else:\n",
    "        temp_prediction=temp_prediction.as_data_frame()['predict']\n",
    "        print('model ',model, \"accuracy \", accuracy_score(train_new['Cover_Type'],temp_prediction),'bal accur',bal_acc2(train_new['Cover_Type'],temp_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### see the weights of the ensemble model - it may hint which models to grab\n",
    "\n",
    "Nope as meta is just weighted avarage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble=h2o.get_model('StackedEnsemble_BestOfFamily_AutoML_20190916_003446')\n",
    "#ensemble.coef_norm #for metalearner to see the weight of each meta model\n",
    "#ensemble.std_coef_plot() #to see the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now I will take 3 best models - one best on accuracy, best on balanced accuracy, best other type of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=h2o.get_model('GBM_4_AutoML_20190916_013019').cross_validation_holdout_predictions().as_data_frame()['predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1680,  347,    2,    0,   25,    3,  103],\n",
       "       [ 337, 1605,   47,    0,  122,   39,   10],\n",
       "       [   0,   14, 1823,   77,   19,  227,    0],\n",
       "       [   0,    0,   27, 2111,    0,   22,    0],\n",
       "       [   3,   47,   29,    0, 2063,   18,    0],\n",
       "       [   1,   29,  142,   41,   11, 1936,    0],\n",
       "       [  57,    6,    1,    0,    0,    0, 2096]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(train_new['Cover_Type'],temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the cross-validation of leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.get_model('GBM_4_AutoML_20190916_013019').cross_validation_holdout_predictions().as_data_frame().to_csv('h20_1_train_prob.csv')\n",
    "h2o.get_model('GBM_3_AutoML_20190916_013019').cross_validation_holdout_predictions().as_data_frame().to_csv('h20_2_train_prob.csv')\n",
    "h2o.get_model('GBM_grid_1_AutoML_20190916_013019_model_7').cross_validation_holdout_predictions().as_data_frame().to_csv('h20_3_train_prob.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "test_new=add_cat(test,soil_type,wild_type,soil_names,hill_feat)\n",
    "test_h2o=h2o.H2OFrame(test_new[learn_cols])\n",
    "test_h2o['soil_cat'] = test_h2o['soil_cat'].asfactor()\n",
    "test_h2o['wild_cat'] = test_h2o['wild_cat'].asfactor()\n",
    "test_h2o['stone_cat'] = test_h2o['stone_cat'].asfactor()\n",
    "test_h2o['world_side'] = test_h2o['world_side'].asfactor()\n",
    "test_h2o['wild_stone'] = test_h2o['wild_stone'].asfactor()\n",
    "test_h2o['soil_wild_cat'] = test_h2o['soil_wild_cat'].asfactor()\n",
    "test_h2o['Rock_cat'] = test_h2o['Rock_cat'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dopefish\\Anaconda3\\envs\\TF2\\lib\\site-packages\\h2o\\job.py:70: UserWarning: Test/Validation dataset column 'soil_cat' has levels not trained on: [6, 14]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Dopefish\\Anaconda3\\envs\\TF2\\lib\\site-packages\\h2o\\job.py:70: UserWarning: Test/Validation dataset column 'wild_stone' has levels not trained on: [31]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Dopefish\\Anaconda3\\envs\\TF2\\lib\\site-packages\\h2o\\job.py:70: UserWarning: Test/Validation dataset column 'soil_wild_cat' has levels not trained on: [60, 143, 151, 171]\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#save the predictions\n",
    "h2o.get_model('GBM_4_AutoML_20190916_013019').predict(test_h2o).as_data_frame().to_csv('h20_1_test_prob.csv')\n",
    "h2o.get_model('GBM_3_AutoML_20190916_013019').predict(test_h2o).as_data_frame().to_csv('h20_2_test_prob.csv')\n",
    "h2o.get_model('GBM_grid_1_AutoML_20190916_013019_model_7').predict(test_h2o).as_data_frame().to_csv('h20_3_test_prob.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/h2oai/h2o-tutorials/blob/master/h2o-world-2017/automl/Python/automl_binary_classification_product_backorders.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Coding\\\\courses\\\\Kaggle\\\\challange\\\\sub 1309\\\\H2O\\\\mpdel_3\\\\GBM_grid_1_AutoML_20190916_013019_model_7'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.save_model(h2o.get_model('GBM_4_AutoML_20190916_013019'), path = \"./H2O/mpdel_1\")\n",
    "h2o.save_model(h2o.get_model('GBM_3_AutoML_20190916_013019'), path = \"./H2O/mpdel_2\")\n",
    "h2o.save_model(h2o.get_model('GBM_grid_1_AutoML_20190916_013019_model_7'), path = \"./H2O/mpdel_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "predict=aml.leader.predict(test_h2o).as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making prediction of leader \n",
    "sub=pd.DataFrame(test.Id.values,columns=['ID'])\n",
    "sub['Cover_Type']=predict['predict'].values.astype('int64')\n",
    "sub.to_csv('h2O.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
