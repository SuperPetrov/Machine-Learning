{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules needed \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import category_encoders\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pred=pd.read_csv(os.path.join(os.getcwd(),'cat_train_prob.csv'))\n",
    "for_pred=pd.read_csv(os.path.join(os.getcwd(),'forest_train_prob.csv'))\n",
    "for_smal_pred=pd.read_csv(os.path.join(os.getcwd(),'forest_smal_train_prob.csv'))\n",
    "NN_pred=pd.read_csv(os.path.join(os.getcwd(),'NN_train_prob.csv'))\n",
    "H2O_1_pred=pd.read_csv(os.path.join(os.getcwd(),'h20_1_train_prob.csv'))\n",
    "H2O_2_pred=pd.read_csv(os.path.join(os.getcwd(),'h20_2_train_prob.csv'))\n",
    "H2O_3_pred=pd.read_csv(os.path.join(os.getcwd(),'h20_3_train_prob.csv'))\n",
    "\n",
    "train=pd.read_csv(os.path.join(os.getcwd(),'train.csv.zip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights={1: 0.37062, 2: 0.49657,3:0.05947,4:0.018,5:0.018,6:0.018,7:0.018}\n",
    "class_weights={1: 0.37053, 2: 0.49657,3:0.05947,4:0.00106,5:0.01287,6:0.02698,7:0.03238}\n",
    "list_weight=compute_class_weight(class_weights,np.unique(train['Cover_Type']),train['Cover_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns\n",
    "target_col='Cover_Type'\n",
    "soil_type=[x for x in train.columns if 'Soil' in x]\n",
    "wild_type=[x for x in train.columns if 'Wilderness' in x]\n",
    "vert_dist=['Vertical_Distance_To_Hydrology']\n",
    "hor_dist=['Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Roadways',  'Horizontal_Distance_To_Fire_Points']\n",
    "hill_feat=['Hillshade_9am', 'Hillshade_Noon','Hillshade_3pm']\n",
    "other_feat=['Elevation', 'Aspect', 'Slope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bal_acc(y_true,y_pred,weights=None):\n",
    "    #weights should be provided as list of weights for each class to sum up to 1\n",
    "    temp1=np.unique(y_true,return_counts=True)[1]\n",
    "    temp2=confusion_matrix(y_true,y_pred)\n",
    "    acc_bal=np.sum(np.diag(temp2)*(temp1/np.sum(temp1))/temp1)\n",
    "    if len(weights)==0:\n",
    "        acc_weig=acc_bal\n",
    "    elif len(weights)!=len(temp1):\n",
    "        print('provide weight for each class')\n",
    "    else:\n",
    "        acc_weig=np.sum(np.diag(temp2)*weights/temp1)\n",
    "    return (acc_weig,acc_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_acc  (0.772510162037037, 0.8607142857142857)\n",
      "for_acc  (0.786329462962963, 0.8853174603174603)\n",
      "NN_acc  (0.7926306018518519, 0.8728174603174602)\n"
     ]
    }
   ],
   "source": [
    "print('cat_acc ',bal_acc(train[target_col].values,(np.argmax(cat_pred.iloc[:,1:].values,1)+1),weights=list_weight))\n",
    "print('for_acc ',bal_acc(train[target_col].values,(np.argmax(for_pred.iloc[:,1:].values,1)+1),weights=list_weight))\n",
    "print('NN_acc ',bal_acc(train[target_col].values,(np.argmax(NN_pred.iloc[:,1:].values,1)+1),weights=list_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O_1_acc  (0.7762913379629628, 0.8805555555555555)\n",
      "H2O_2_acc  (0.7755452962962962, 0.879100529100529)\n",
      "H2O_3_acc  (0.7745515370370372, 0.8794973544973544)\n"
     ]
    }
   ],
   "source": [
    "print('H2O_1_acc ',bal_acc(train[target_col].values,(np.argmax(H2O_1_pred.iloc[:,2:].values,1)+1),weights=list_weight))\n",
    "print('H2O_2_acc ',bal_acc(train[target_col].values,(np.argmax(H2O_2_pred.iloc[:,2:].values,1)+1),weights=list_weight))\n",
    "print('H2O_3_acc ',bal_acc(train[target_col].values,(np.argmax(H2O_3_pred.iloc[:,2:].values,1)+1),weights=list_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=cat_pred.iloc[:,1:].values+for_pred.iloc[:,1:].values+NN_pred.iloc[:,1:].values+H2O_1_pred.iloc[:,2:].values+H2O_2_pred.iloc[:,2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_acc  (0.801738449074074, 0.89265873015873)\n"
     ]
    }
   ],
   "source": [
    "print('mean_acc ',bal_acc(train[target_col].values,(np.argmax(temp,1)+1),weights=list_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=np.hstack([cat_pred.iloc[:,1:].values,for_pred.iloc[:,1:].values,for_smal_pred.iloc[:,1:].values,NN_pred.iloc[:,1:].values,H2O_1_pred.iloc[:,2:].values,H2O_2_pred.iloc[:,2:].values,H2O_3_pred.iloc[:,2:].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first I split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, train[target_col], stratify=train[target_col],  test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one more time but this version will be needed for cross validation\n",
    "from sklearn.metrics import make_scorer\n",
    "def bal_acc2(y_true,y_pred):\n",
    "    #weights should be provided as list of weights for each class to sum up to 1\n",
    "    temp1=np.unique(y_true,return_counts=True)[1]\n",
    "    temp2=confusion_matrix(y_true,y_pred)\n",
    "    acc_bal=np.sum(np.diag(temp2)*(temp1/np.sum(temp1))/temp1)\n",
    "    weights=[0.37053, 0.49657, 0.05947, 0.00106, 0.01287, 0.02698, 0.03238]\n",
    "    acc_weig=np.sum(np.diag(temp2)*weights/temp1)\n",
    "    return (acc_weig)\n",
    "\n",
    "my_score = make_scorer(bal_acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bayes_RandomTrees2(n_estimators, max_depth,max_features):\n",
    "    \n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "    \n",
    "    assert type(n_estimators) == int\n",
    "    assert type(max_depth) == int\n",
    "\n",
    "    #etc =RandomForestClassifier(n_estimators = n_estimators,max_features = max_features,bootstrap = False,max_depth=max_depth,verbose=0,n_jobs=-1,random_state=42)\n",
    "    etc =RandomForestClassifier(n_estimators = n_estimators,max_features = max_features,bootstrap = False,max_depth=max_depth,verbose=0,n_jobs=-1,class_weight=class_weights,random_state=42)\n",
    "    etc.fit(X_train, y_train)\n",
    "    \n",
    "    score = bal_acc2(y_val, etc.predict(X_val))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['max_depth', 'max_features', 'n_estimators']\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : (80, 400),\n",
    "          'max_depth' : (5, 50),\n",
    "          'max_features' : (.05,0.9)} \n",
    "\n",
    "RandomTreeBO = BayesianOptimization(Bayes_RandomTrees2, params, random_state = 42)\n",
    "\n",
    "print(RandomTreeBO.space.keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_points = 50\n",
    "n_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7876  \u001b[0m | \u001b[0m 21.85   \u001b[0m | \u001b[0m 0.8581  \u001b[0m | \u001b[0m 314.2   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.796   \u001b[0m | \u001b[95m 31.94   \u001b[0m | \u001b[95m 0.1826  \u001b[0m | \u001b[95m 129.9   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.8237  \u001b[0m | \u001b[95m 7.614   \u001b[0m | \u001b[95m 0.7862  \u001b[0m | \u001b[95m 272.4   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7914  \u001b[0m | \u001b[0m 36.86   \u001b[0m | \u001b[0m 0.0675  \u001b[0m | \u001b[0m 390.4   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8044  \u001b[0m | \u001b[0m 42.46   \u001b[0m | \u001b[0m 0.2305  \u001b[0m | \u001b[0m 138.2   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8171  \u001b[0m | \u001b[0m 13.25   \u001b[0m | \u001b[0m 0.3086  \u001b[0m | \u001b[0m 247.9   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 24.44   \u001b[0m | \u001b[0m 0.2975  \u001b[0m | \u001b[0m 275.8   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8237  \u001b[0m | \u001b[0m 11.28   \u001b[0m | \u001b[0m 0.2983  \u001b[0m | \u001b[0m 197.2   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7989  \u001b[0m | \u001b[0m 25.52   \u001b[0m | \u001b[0m 0.7174  \u001b[0m | \u001b[0m 143.9   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7989  \u001b[0m | \u001b[0m 28.14   \u001b[0m | \u001b[0m 0.5536  \u001b[0m | \u001b[0m 94.86   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.798   \u001b[0m | \u001b[0m 32.34   \u001b[0m | \u001b[0m 0.1949  \u001b[0m | \u001b[0m 100.8   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7642  \u001b[0m | \u001b[0m 47.7    \u001b[0m | \u001b[0m 0.8708  \u001b[0m | \u001b[0m 338.7   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8067  \u001b[0m | \u001b[0m 18.71   \u001b[0m | \u001b[0m 0.133   \u001b[0m | \u001b[0m 299.0   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8024  \u001b[0m | \u001b[0m 24.81   \u001b[0m | \u001b[0m 0.1537  \u001b[0m | \u001b[0m 238.5   \u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m 0.8313  \u001b[0m | \u001b[95m 6.547   \u001b[0m | \u001b[95m 0.8229  \u001b[0m | \u001b[95m 162.8   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7979  \u001b[0m | \u001b[0m 34.81   \u001b[0m | \u001b[0m 0.315   \u001b[0m | \u001b[0m 246.4   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7969  \u001b[0m | \u001b[0m 29.6    \u001b[0m | \u001b[0m 0.2071  \u001b[0m | \u001b[0m 390.3   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7705  \u001b[0m | \u001b[0m 39.88   \u001b[0m | \u001b[0m 0.8486  \u001b[0m | \u001b[0m 366.3   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 31.91   \u001b[0m | \u001b[0m 0.8336  \u001b[0m | \u001b[0m 108.3   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.818   \u001b[0m | \u001b[0m 13.82   \u001b[0m | \u001b[0m 0.08844 \u001b[0m | \u001b[0m 184.1   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.8012  \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 0.2806  \u001b[0m | \u001b[0m 345.2   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8009  \u001b[0m | \u001b[0m 21.05   \u001b[0m | \u001b[0m 0.2888  \u001b[0m | \u001b[0m 253.7   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8242  \u001b[0m | \u001b[0m 11.34   \u001b[0m | \u001b[0m 0.7319  \u001b[0m | \u001b[0m 103.9   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7928  \u001b[0m | \u001b[0m 49.41   \u001b[0m | \u001b[0m 0.7064  \u001b[0m | \u001b[0m 143.6   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8257  \u001b[0m | \u001b[0m 5.248   \u001b[0m | \u001b[0m 0.7431  \u001b[0m | \u001b[0m 306.2   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 37.81   \u001b[0m | \u001b[0m 0.7056  \u001b[0m | \u001b[0m 103.7   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.8003  \u001b[0m | \u001b[0m 21.13   \u001b[0m | \u001b[0m 0.1485  \u001b[0m | \u001b[0m 356.2   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.792   \u001b[0m | \u001b[0m 33.05   \u001b[0m | \u001b[0m 0.3313  \u001b[0m | \u001b[0m 100.3   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.8111  \u001b[0m | \u001b[0m 18.99   \u001b[0m | \u001b[0m 0.3264  \u001b[0m | \u001b[0m 313.5   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7806  \u001b[0m | \u001b[0m 33.69   \u001b[0m | \u001b[0m 0.8041  \u001b[0m | \u001b[0m 231.1   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.8259  \u001b[0m | \u001b[0m 10.38   \u001b[0m | \u001b[0m 0.6563  \u001b[0m | \u001b[0m 323.5   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7878  \u001b[0m | \u001b[0m 30.26   \u001b[0m | \u001b[0m 0.7053  \u001b[0m | \u001b[0m 238.0   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.7993  \u001b[0m | \u001b[0m 28.52   \u001b[0m | \u001b[0m 0.4134  \u001b[0m | \u001b[0m 88.13   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.8229  \u001b[0m | \u001b[0m 9.855   \u001b[0m | \u001b[0m 0.07671 \u001b[0m | \u001b[0m 283.7   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.8083  \u001b[0m | \u001b[0m 19.15   \u001b[0m | \u001b[0m 0.4823  \u001b[0m | \u001b[0m 370.4   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.8095  \u001b[0m | \u001b[0m 16.22   \u001b[0m | \u001b[0m 0.3988  \u001b[0m | \u001b[0m 321.8   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 15.3    \u001b[0m | \u001b[0m 0.1154  \u001b[0m | \u001b[0m 172.7   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 12.25   \u001b[0m | \u001b[0m 0.8402  \u001b[0m | \u001b[0m 338.6   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7838  \u001b[0m | \u001b[0m 33.5    \u001b[0m | \u001b[0m 0.7907  \u001b[0m | \u001b[0m 337.2   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.8081  \u001b[0m | \u001b[0m 13.4    \u001b[0m | \u001b[0m 0.8087  \u001b[0m | \u001b[0m 252.6   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7828  \u001b[0m | \u001b[0m 41.33   \u001b[0m | \u001b[0m 0.8117  \u001b[0m | \u001b[0m 181.8   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.8272  \u001b[0m | \u001b[0m 9.952   \u001b[0m | \u001b[0m 0.2437  \u001b[0m | \u001b[0m 216.7   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.7878  \u001b[0m | \u001b[0m 41.81   \u001b[0m | \u001b[0m 0.7816  \u001b[0m | \u001b[0m 82.22   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.797   \u001b[0m | \u001b[0m 27.98   \u001b[0m | \u001b[0m 0.4048  \u001b[0m | \u001b[0m 151.1   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.8248  \u001b[0m | \u001b[0m 10.39   \u001b[0m | \u001b[0m 0.337   \u001b[0m | \u001b[0m 381.7   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.8061  \u001b[0m | \u001b[0m 19.54   \u001b[0m | \u001b[0m 0.491   \u001b[0m | \u001b[0m 305.0   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7806  \u001b[0m | \u001b[0m 21.36   \u001b[0m | \u001b[0m 0.876   \u001b[0m | \u001b[0m 388.0   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.8162  \u001b[0m | \u001b[0m 16.33   \u001b[0m | \u001b[0m 0.4727  \u001b[0m | \u001b[0m 176.3   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.8039  \u001b[0m | \u001b[0m 17.82   \u001b[0m | \u001b[0m 0.08135 \u001b[0m | \u001b[0m 275.1   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7935  \u001b[0m | \u001b[0m 27.62   \u001b[0m | \u001b[0m 0.09376 \u001b[0m | \u001b[0m 169.2   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.8277  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.2094  \u001b[0m | \u001b[0m 80.0    \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.797   \u001b[0m | \u001b[0m 49.86   \u001b[0m | \u001b[0m 0.1369  \u001b[0m | \u001b[0m 280.0   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.8009  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 131.6   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.8109  \u001b[0m | \u001b[0m 5.007   \u001b[0m | \u001b[0m 0.1289  \u001b[0m | \u001b[0m 399.2   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.7995  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 356.7   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.7992  \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.125   \u001b[0m | \u001b[0m 113.8   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.8028  \u001b[0m | \u001b[0m 5.077   \u001b[0m | \u001b[0m 0.05174 \u001b[0m | \u001b[0m 93.92   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.797   \u001b[0m | \u001b[0m 49.87   \u001b[0m | \u001b[0m 0.1315  \u001b[0m | \u001b[0m 260.4   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.8213  \u001b[0m | \u001b[0m 5.016   \u001b[0m | \u001b[0m 0.1702  \u001b[0m | \u001b[0m 233.2   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.798   \u001b[0m | \u001b[0m 27.32   \u001b[0m | \u001b[0m 0.07733 \u001b[0m | \u001b[0m 202.8   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.7994  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 330.8   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.7945  \u001b[0m | \u001b[0m 49.74   \u001b[0m | \u001b[0m 0.2283  \u001b[0m | \u001b[0m 399.7   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.7944  \u001b[0m | \u001b[0m 49.99   \u001b[0m | \u001b[0m 0.2911  \u001b[0m | \u001b[0m 211.2   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.823   \u001b[0m | \u001b[0m 5.005   \u001b[0m | \u001b[0m 0.8721  \u001b[0m | \u001b[0m 181.0   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.7947  \u001b[0m | \u001b[0m 49.88   \u001b[0m | \u001b[0m 0.06307 \u001b[0m | \u001b[0m 91.87   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.7942  \u001b[0m | \u001b[0m 32.16   \u001b[0m | \u001b[0m 0.08274 \u001b[0m | \u001b[0m 399.8   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.8101  \u001b[0m | \u001b[0m 16.41   \u001b[0m | \u001b[0m 0.0674  \u001b[0m | \u001b[0m 80.14   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.8251  \u001b[0m | \u001b[0m 5.061   \u001b[0m | \u001b[0m 0.7704  \u001b[0m | \u001b[0m 376.1   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.8029  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 257.9   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.7946  \u001b[0m | \u001b[0m 49.99   \u001b[0m | \u001b[0m 0.2903  \u001b[0m | \u001b[0m 236.9   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.8214  \u001b[0m | \u001b[0m 5.169   \u001b[0m | \u001b[0m 0.201   \u001b[0m | \u001b[0m 114.4   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.8222  \u001b[0m | \u001b[0m 5.185   \u001b[0m | \u001b[0m 0.8858  \u001b[0m | \u001b[0m 207.6   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.8006  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 151.7   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.8236  \u001b[0m | \u001b[0m 5.178   \u001b[0m | \u001b[0m 0.2099  \u001b[0m | \u001b[0m 386.0   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.8003  \u001b[0m | \u001b[0m 13.63   \u001b[0m | \u001b[0m 0.8766  \u001b[0m | \u001b[0m 227.7   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.7857  \u001b[0m | \u001b[0m 49.91   \u001b[0m | \u001b[0m 0.06937 \u001b[0m | \u001b[0m 165.2   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.8186  \u001b[0m | \u001b[0m 8.885   \u001b[0m | \u001b[0m 0.07868 \u001b[0m | \u001b[0m 313.0   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.8296  \u001b[0m | \u001b[0m 5.013   \u001b[0m | \u001b[0m 0.6445  \u001b[0m | \u001b[0m 290.9   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.7989  \u001b[0m | \u001b[0m 49.95   \u001b[0m | \u001b[0m 0.1021  \u001b[0m | \u001b[0m 356.7   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.8162  \u001b[0m | \u001b[0m 13.31   \u001b[0m | \u001b[0m 0.06652 \u001b[0m | \u001b[0m 119.7   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.8267  \u001b[0m | \u001b[0m 5.024   \u001b[0m | \u001b[0m 0.2975  \u001b[0m | \u001b[0m 170.7   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.816   \u001b[0m | \u001b[0m 9.638   \u001b[0m | \u001b[0m 0.8925  \u001b[0m | \u001b[0m 299.2   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.7972  \u001b[0m | \u001b[0m 49.79   \u001b[0m | \u001b[0m 0.1389  \u001b[0m | \u001b[0m 379.0   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.803   \u001b[0m | \u001b[0m 5.091   \u001b[0m | \u001b[0m 0.06611 \u001b[0m | \u001b[0m 279.6   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.7995  \u001b[0m | \u001b[0m 49.79   \u001b[0m | \u001b[0m 0.1086  \u001b[0m | \u001b[0m 299.7   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 37.01   \u001b[0m | \u001b[0m 0.05788 \u001b[0m | \u001b[0m 290.6   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.7987  \u001b[0m | \u001b[0m 49.9    \u001b[0m | \u001b[0m 0.245   \u001b[0m | \u001b[0m 194.0   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.7971  \u001b[0m | \u001b[0m 49.81   \u001b[0m | \u001b[0m 0.1575  \u001b[0m | \u001b[0m 80.05   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.8093  \u001b[0m | \u001b[0m 7.637   \u001b[0m | \u001b[0m 0.05066 \u001b[0m | \u001b[0m 370.8   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.7952  \u001b[0m | \u001b[0m 13.69   \u001b[0m | \u001b[0m 0.8963  \u001b[0m | \u001b[0m 207.5   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.8024  \u001b[0m | \u001b[0m 5.114   \u001b[0m | \u001b[0m 0.08019 \u001b[0m | \u001b[0m 219.9   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.8199  \u001b[0m | \u001b[0m 5.4     \u001b[0m | \u001b[0m 0.1657  \u001b[0m | \u001b[0m 194.8   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.82    \u001b[0m | \u001b[0m 5.191   \u001b[0m | \u001b[0m 0.8559  \u001b[0m | \u001b[0m 242.6   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.7914  \u001b[0m | \u001b[0m 49.76   \u001b[0m | \u001b[0m 0.0528  \u001b[0m | \u001b[0m 317.2   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.7916  \u001b[0m | \u001b[0m 39.22   \u001b[0m | \u001b[0m 0.05296 \u001b[0m | \u001b[0m 268.4   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 27.47   \u001b[0m | \u001b[0m 0.1082  \u001b[0m | \u001b[0m 189.0   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.7934  \u001b[0m | \u001b[0m 40.02   \u001b[0m | \u001b[0m 0.06518 \u001b[0m | \u001b[0m 204.0   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.8048  \u001b[0m | \u001b[0m 17.71   \u001b[0m | \u001b[0m 0.05413 \u001b[0m | \u001b[0m 98.11   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.7883  \u001b[0m | \u001b[0m 49.74   \u001b[0m | \u001b[0m 0.08141 \u001b[0m | \u001b[0m 129.3   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.7825  \u001b[0m | \u001b[0m 16.67   \u001b[0m | \u001b[0m 0.8957  \u001b[0m | \u001b[0m 287.3   \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.8158  \u001b[0m | \u001b[0m 11.39   \u001b[0m | \u001b[0m 0.1051  \u001b[0m | \u001b[0m 265.8   \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.8018  \u001b[0m | \u001b[0m 5.053   \u001b[0m | \u001b[0m 0.06362 \u001b[0m | \u001b[0m 104.3   \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 0.8028  \u001b[0m | \u001b[0m 5.306   \u001b[0m | \u001b[0m 0.05074 \u001b[0m | \u001b[0m 297.5   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 0.7577  \u001b[0m | \u001b[0m 41.48   \u001b[0m | \u001b[0m 0.8973  \u001b[0m | \u001b[0m 156.2   \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 0.7869  \u001b[0m | \u001b[0m 49.95   \u001b[0m | \u001b[0m 0.0723  \u001b[0m | \u001b[0m 181.0   \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 0.7817  \u001b[0m | \u001b[0m 16.01   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 155.2   \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 36.6    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 350.8   \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 0.7963  \u001b[0m | \u001b[0m 24.98   \u001b[0m | \u001b[0m 0.06839 \u001b[0m | \u001b[0m 219.4   \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 0.8157  \u001b[0m | \u001b[0m 13.66   \u001b[0m | \u001b[0m 0.05326 \u001b[0m | \u001b[0m 110.2   \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 0.8232  \u001b[0m | \u001b[0m 5.124   \u001b[0m | \u001b[0m 0.8282  \u001b[0m | \u001b[0m 122.2   \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 0.8178  \u001b[0m | \u001b[0m 10.17   \u001b[0m | \u001b[0m 0.8913  \u001b[0m | \u001b[0m 85.05   \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 49.23   \u001b[0m | \u001b[0m 0.06165 \u001b[0m | \u001b[0m 247.8   \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 0.7939  \u001b[0m | \u001b[0m 48.71   \u001b[0m | \u001b[0m 0.06204 \u001b[0m | \u001b[0m 223.5   \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 0.8188  \u001b[0m | \u001b[0m 5.086   \u001b[0m | \u001b[0m 0.8894  \u001b[0m | \u001b[0m 319.7   \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 0.8144  \u001b[0m | \u001b[0m 11.18   \u001b[0m | \u001b[0m 0.06102 \u001b[0m | \u001b[0m 238.7   \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 0.8078  \u001b[0m | \u001b[0m 16.43   \u001b[0m | \u001b[0m 0.08833 \u001b[0m | \u001b[0m 400.0   \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 0.7963  \u001b[0m | \u001b[0m 49.88   \u001b[0m | \u001b[0m 0.1023  \u001b[0m | \u001b[0m 102.9   \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 30.73   \u001b[0m | \u001b[0m 0.05385 \u001b[0m | \u001b[0m 376.6   \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 0.819   \u001b[0m | \u001b[0m 5.067   \u001b[0m | \u001b[0m 0.8982  \u001b[0m | \u001b[0m 80.14   \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 0.8189  \u001b[0m | \u001b[0m 5.009   \u001b[0m | \u001b[0m 0.8966  \u001b[0m | \u001b[0m 343.9   \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 0.8072  \u001b[0m | \u001b[0m 6.22    \u001b[0m | \u001b[0m 0.0562  \u001b[0m | \u001b[0m 204.1   \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 0.8131  \u001b[0m | \u001b[0m 11.81   \u001b[0m | \u001b[0m 0.8811  \u001b[0m | \u001b[0m 190.7   \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 0.8048  \u001b[0m | \u001b[0m 13.88   \u001b[0m | \u001b[0m 0.8804  \u001b[0m | \u001b[0m 131.5   \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 0.8097  \u001b[0m | \u001b[0m 11.86   \u001b[0m | \u001b[0m 0.8944  \u001b[0m | \u001b[0m 350.9   \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 0.8266  \u001b[0m | \u001b[0m 5.029   \u001b[0m | \u001b[0m 0.2264  \u001b[0m | \u001b[0m 162.1   \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 0.8154  \u001b[0m | \u001b[0m 9.149   \u001b[0m | \u001b[0m 0.8865  \u001b[0m | \u001b[0m 116.3   \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 0.7906  \u001b[0m | \u001b[0m 49.97   \u001b[0m | \u001b[0m 0.05635 \u001b[0m | \u001b[0m 390.8   \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 0.8309  \u001b[0m | \u001b[0m 6.943   \u001b[0m | \u001b[0m 0.895   \u001b[0m | \u001b[0m 286.7   \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 0.808   \u001b[0m | \u001b[0m 12.66   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 310.9   \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 0.7906  \u001b[0m | \u001b[0m 41.29   \u001b[0m | \u001b[0m 0.0527  \u001b[0m | \u001b[0m 308.6   \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 0.7916  \u001b[0m | \u001b[0m 40.5    \u001b[0m | \u001b[0m 0.0541  \u001b[0m | \u001b[0m 327.3   \u001b[0m |\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 0.8033  \u001b[0m | \u001b[0m 5.763   \u001b[0m | \u001b[0m 0.07458 \u001b[0m | \u001b[0m 379.1   \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 0.819   \u001b[0m | \u001b[0m 8.789   \u001b[0m | \u001b[0m 0.8774  \u001b[0m | \u001b[0m 393.7   \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 0.8207  \u001b[0m | \u001b[0m 8.297   \u001b[0m | \u001b[0m 0.8964  \u001b[0m | \u001b[0m 364.3   \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 0.8103  \u001b[0m | \u001b[0m 11.57   \u001b[0m | \u001b[0m 0.8963  \u001b[0m | \u001b[0m 376.1   \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 0.7932  \u001b[0m | \u001b[0m 41.89   \u001b[0m | \u001b[0m 0.05072 \u001b[0m | \u001b[0m 116.7   \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 5.054   \u001b[0m | \u001b[0m 0.8787  \u001b[0m | \u001b[0m 368.6   \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 0.818   \u001b[0m | \u001b[0m 8.528   \u001b[0m | \u001b[0m 0.8725  \u001b[0m | \u001b[0m 386.1   \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 0.7922  \u001b[0m | \u001b[0m 49.8    \u001b[0m | \u001b[0m 0.08132 \u001b[0m | \u001b[0m 368.5   \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 0.7956  \u001b[0m | \u001b[0m 27.8    \u001b[0m | \u001b[0m 0.1199  \u001b[0m | \u001b[0m 264.7   \u001b[0m |\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 0.7915  \u001b[0m | \u001b[0m 37.05   \u001b[0m | \u001b[0m 0.07849 \u001b[0m | \u001b[0m 215.5   \u001b[0m |\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 0.798   \u001b[0m | \u001b[0m 34.23   \u001b[0m | \u001b[0m 0.06484 \u001b[0m | \u001b[0m 142.3   \u001b[0m |\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 0.7928  \u001b[0m | \u001b[0m 32.74   \u001b[0m | \u001b[0m 0.08922 \u001b[0m | \u001b[0m 80.08   \u001b[0m |\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m 0.8121  \u001b[0m | \u001b[0m 5.237   \u001b[0m | \u001b[0m 0.1237  \u001b[0m | \u001b[0m 393.1   \u001b[0m |\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 0.7901  \u001b[0m | \u001b[0m 36.96   \u001b[0m | \u001b[0m 0.08673 \u001b[0m | \u001b[0m 279.8   \u001b[0m |\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m 0.7905  \u001b[0m | \u001b[0m 49.94   \u001b[0m | \u001b[0m 0.05144 \u001b[0m | \u001b[0m 291.1   \u001b[0m |\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 0.7965  \u001b[0m | \u001b[0m 22.19   \u001b[0m | \u001b[0m 0.05031 \u001b[0m | \u001b[0m 333.2   \u001b[0m |\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 0.821   \u001b[0m | \u001b[0m 5.018   \u001b[0m | \u001b[0m 0.8736  \u001b[0m | \u001b[0m 166.1   \u001b[0m |\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m 0.824   \u001b[0m | \u001b[0m 9.054   \u001b[0m | \u001b[0m 0.1295  \u001b[0m | \u001b[0m 176.1   \u001b[0m |\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m 0.8128  \u001b[0m | \u001b[0m 9.651   \u001b[0m | \u001b[0m 0.05502 \u001b[0m | \u001b[0m 163.0   \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "RandomTreeBO.maximize(init_points = init_points,  n_iter = n_iter,   acq = 'ucb',    xi = 0.0,        alpha = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.8312958564814816, 'params': {'max_depth': 6.547483450184828, 'max_features': 0.8229223417669648, 'n_estimators': 162.8095941120054}}\n"
     ]
    }
   ],
   "source": [
    "print(RandomTreeBO.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False,\n",
       "                       class_weight={1: 0.37053, 2: 0.49657, 3: 0.05947,\n",
       "                                     4: 0.00106, 5: 0.01287, 6: 0.02698,\n",
       "                                     7: 0.03238},\n",
       "                       criterion='gini', max_depth=8, max_features=0.9,\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest=RandomForestClassifier(n_estimators = 300,max_features = 0.9,bootstrap = False,max_depth=8,class_weight=class_weights)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special acc is:  (0.9157917476851852, 0.7321428571428571)\n"
     ]
    }
   ],
   "source": [
    "#the accuracy of validation\n",
    "print(\"special acc is: \",bal_acc(y_train,forest.predict(X_train),weights=list_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=forest.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special acc is:  (0.8186674305555555, 0.689484126984127)\n"
     ]
    }
   ],
   "source": [
    "#the accuracy of validation\n",
    "print(\"special acc is: \",bal_acc(y_val,predict,weights=list_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are: special acc is:  (0.8186674305555555, 0.689484126984127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_2=RandomForestClassifier(n_estimators = 300,max_features = 0.9,bootstrap = False,max_depth=8,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossValidationscores = cross_val_score(forest_2, X_data, train[target_col], cv=5, scoring = my_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8202221712962963"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(CrossValidationscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV of 5+1 model 0.8202221712962963\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now adding the Gaussian Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(os.path.join(os.getcwd(),'test.csv.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "features_cluster=soil_type+wild_type+hor_dist+['Elevation']\n",
    "gmix = GaussianMixture(n_components=11)\n",
    "gmix.fit(test[features_cluster])\n",
    "\n",
    "temp_train_cluster = gmix.predict(train[features_cluster])\n",
    "temp_test_cluster = gmix.predict(test[features_cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_data_3=np.hstack([cat_pred.iloc[:,1:].values,for_pred.iloc[:,1:].values,NN_pred.iloc[:,1:].values])\n",
    "#X_data_3=np.hstack([X_data,np.expand_dims(temp_train_cluster,-1)])\n",
    "X_data_3=X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_3=RandomForestClassifier(n_estimators = 300,max_features = 'auto',bootstrap = False,max_depth=7,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossValidationscores_2 = cross_val_score(forest_3, X_data_3, train_new[target_col], cv=5, scoring = my_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.828467412037037"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(CrossValidationscores_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making final prediction with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pred_test=pd.read_csv(os.path.join(os.getcwd(),'cat_test_prob.csv'))\n",
    "for_pred_test=pd.read_csv(os.path.join(os.getcwd(),'forest_test_prob.csv'))\n",
    "for_smal_pred_test=pd.read_csv(os.path.join(os.getcwd(),'forest_smal_test_prob.csv'))\n",
    "NN_pred_test=pd.read_csv(os.path.join(os.getcwd(),'NN_test_prob.csv'))\n",
    "H2O_1_test_pred=pd.read_csv(os.path.join(os.getcwd(),'h20_1_test_prob.csv'))\n",
    "H2O_2_test_pred=pd.read_csv(os.path.join(os.getcwd(),'h20_2_test_prob.csv'))\n",
    "H2O_3_test_pred=pd.read_csv(os.path.join(os.getcwd(),'h20_3_test_prob.csv'))\n",
    "X_test=np.hstack([cat_pred_test.iloc[:,1:].values,for_pred_test.iloc[:,1:].values,for_smal_pred_test.iloc[:,1:].values,NN_pred_test.iloc[:,1:].values,H2O_1_test_pred.iloc[:,2:].values,H2O_2_test_pred.iloc[:,2:].values,H2O_3_test_pred.iloc[:,2:].values])\n",
    "#X_test=np.hstack([X_test,np.expand_dims(temp_test_cluster,-1)])\n",
    "test=pd.read_csv(os.path.join(os.getcwd(),'test.csv.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_forest(data_train,y_train,data_val,bagg=10):\n",
    "    temp_result=[]\n",
    "    for i in range(bagg):\n",
    "        forest_model=RandomForestClassifier(n_estimators = 300,max_features = 0.9,bootstrap = False,max_depth=8,class_weight=class_weights,verbose=0,random_state=i*10)\n",
    "        #forest_model=RandomForestClassifier(n_estimators = 100,max_features = 'auto',bootstrap = False,max_depth=87,verbose=0,class_weight=class_weights,random_state=i*10)\n",
    "        forest_model.fit(data_train, y_train)\n",
    "        temp_result.append(forest_model.predict_proba(data_val))\n",
    "        print(i,' fit finished')\n",
    "    return np.mean(temp_result,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  fit finished\n",
      "1  fit finished\n",
      "2  fit finished\n",
      "3  fit finished\n",
      "4  fit finished\n",
      "5  fit finished\n",
      "6  fit finished\n",
      "7  fit finished\n",
      "8  fit finished\n",
      "9  fit finished\n"
     ]
    }
   ],
   "source": [
    "forest_full=train_forest(X_data,train[target_col],X_test,bagg=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=np.argmax(forest_full,axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.DataFrame(test.Id.values,columns=['ID'])\n",
    "sub['Cover_Type']=pred_test\n",
    "sub.to_csv('merged_forest_tuned.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result 0.83316"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
